{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "\n",
    "path_to_data = \"./Data_Filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix\n",
    "\n",
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc\n",
    "\n",
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=100, random_state=2, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ThanhPho dataset\n",
      "Load Nha dataset\n",
      "Load Me dataset\n",
      "Load YTe dataset\n",
      "Load Hoc dataset\n",
      "Load test_ThanhPho dataset\n",
      "Load test_Nha dataset\n",
      "Load test_Me dataset\n",
      "Load test_YTe dataset\n",
      "Load test_Hoc dataset\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"ThanhPho\", \"Nha\", \"Me\", \"YTe\", \"Hoc\", \"test_ThanhPho\", \"test_Nha\", \"test_Me\", \"test_YTe\", \"test_Hoc\"]\n",
    "\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(path_to_data, cname))\n",
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (55545, 36)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f17a804b49cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vectors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Run K-Means algorithm to get clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"centers\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-dde1a0491616>\u001b[0m in \u001b[0;36mclustering\u001b[1;34m(X, n_clusters)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"centers\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m                     \u001b[0mprecompute_distances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m                     x_squared_norms=x_squared_norms, random_state=seed)\n\u001b[0m\u001b[0;32m    938\u001b[0m                 \u001b[1;31m# determine if these results are the best so far\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[1;34m(X, sample_weight, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[0;32m    320\u001b[0m     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,\n\u001b[0;32m    321\u001b[0m                                             \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0minertia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\cluster\\_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;31m# Pairwise distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m def euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False,\n\u001b[0m\u001b[0;32m    196\u001b[0m                         X_norm_squared=None):\n\u001b[0;32m    197\u001b[0m     \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items() if k[:4]!='test'], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_components = {\n",
    "    #  ɲa̤ː˨˩ -> 2 âm vị -> 6 states\n",
    "    \"Nha\": 6,\n",
    "    #  mɛ̰ʔ˨˩ -> 2 âm vị -> 6 states\n",
    "    \"Me\": 6,\n",
    "    #  i˧˧ te˧˥ -> 3 âm vị -> 9 states\n",
    "    \"YTe\": 9,\n",
    "    #   tʰa̤jŋ˨˩ fo˧˥ -> 5 âm vị -> 15 states\n",
    "    \"ThanhPho\": 15,\n",
    "    #  ha̰ʔwk˨ -> 3 âm vị -> 9 states\n",
    "    \"Hoc\": 9,\n",
    "}\n",
    "\n",
    "dict_startprob = {\n",
    "    #  ɲa̤ː˨˩ -> 2 âm vị -> 6 states\n",
    "    \"Nha\": [0.2, 0.8, 0.0, 0.0, 0.0, 0.0,], \n",
    "    \n",
    "    #  mɛ̰ʔ˨˩ -> 2 âm vị -> 6 states\n",
    "    \"Me\": [0.2, 0.6, 0.2, 0.0, 0.0, 0.0,],\n",
    "    \n",
    "    #  i˧˧ te˧˥ -> 3 âm vị -> 9 states\n",
    "    \"YTe\": [0.2, 0.7, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "    \n",
    "    #   tʰa̤jŋ˨˩ fo˧˥ -> 5 âm vị -> 15 states\n",
    "    \"ThanhPho\": [0.1, 0.7, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "    \n",
    "    #  ha̰ʔwk˨ -> 3 âm vị -> 9 states\n",
    "    \"Hoc\": [0.1, 0.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "}\n",
    "\n",
    "dict_transmat = {\n",
    "    #  ɲa̤ː˨˩ \n",
    "    \"Nha\": [[0.2, 0.7, 0.1, 0.0, 0.0, 0.0,], \n",
    "            [0.0, 0.1, 0.8, 0.1, 0.0, 0.0,], \n",
    "            [0.0, 0.0, 0.1, 0.9, 0.0, 0.0,], \n",
    "            [0.0, 0.0, 0.0, 0.1, 0.6, 0.3,], \n",
    "            [0.0, 0.0, 0.0, 0.0, 0.4, 0.5,], \n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 1.0,],], \n",
    "    \n",
    "    #  mɛ̰ʔ˨˩ \n",
    "    \"Me\":  [[0.3, 0.4, 0.3, 0.0, 0.0, 0.0,], \n",
    "            [0.0, 0.2, 0.4, 0.4, 0.0, 0.0,], \n",
    "            [0.0, 0.0, 0.3, 0.4, 0.3, 0.0,], \n",
    "            [0.0, 0.0, 0.0, 0.3, 0.3, 0.4,], \n",
    "            [0.0, 0.0, 0.0, 0.0, 0.3, 0.7,], \n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.6,],], \n",
    "    \n",
    "    #  i˧˧ te˧˥ \n",
    "    \"YTe\": [[0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.6, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.4, 0.4, 0.2, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.3, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.3, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.7, 0.1,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.8,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,],],\n",
    "    \n",
    "    #   tʰa̤jŋ˨˩ fo˧˥ \n",
    "    \"ThanhPho\": [[0.1, 0.7, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.2, 0.6, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.1, 0.7, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.2, 0.5, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.3, 0.5, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.5, 0.2, 0.0, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.7, 0.15, 0.0, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 0.2, 0.0, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.7, 0.1, 0.0,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 0.1,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7,],\n",
    "                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4,],],\n",
    "    \n",
    "    #  ha̰ʔwk˨ \n",
    "    \"Hoc\": [[0.3, 0.6, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.4, 0.5, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.4, 0.4, 0.2, 0.0, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.3, 0.0, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.3, 0.0,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.2, 0.1,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3,],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2,],],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "for cname in class_names:\n",
    "    class_vectors = dataset[cname]\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['one'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "    dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "    \n",
    "    if cname[:4] != 'test':\n",
    "        hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "            n_components=6, random_state=0, n_iter=1000, verbose=True,\n",
    "            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n",
    "            transmat_prior=np.array([\n",
    "                [0.1,0.5,0.1,0.1,0.1,0.1,],\n",
    "                [0.1,0.1,0.5,0.1,0.1,0.1,],\n",
    "                [0.1,0.1,0.1,0.5,0.1,0.1,],\n",
    "                [0.1,0.1,0.1,0.1,0.5,0.1,],\n",
    "                [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "                [0.1,0.1,0.1,0.1,0.1,0.5,],\n",
    "            ]),\n",
    "        )\n",
    "    \n",
    "        X = np.concatenate(dataset[cname])\n",
    "        lengths = list([len(x) for x in dataset[cname]])\n",
    "        print(\"training class\", cname)\n",
    "        print(X.shape, lengths, len(lengths))\n",
    "        hmm.fit(X, lengths=lengths)\n",
    "        models[cname] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_score(score):\n",
    "    res = \"None\";\n",
    "    for e in score:\n",
    "        if res == \"None\":\n",
    "            res = e\n",
    "        else:\n",
    "            if (score[e]>score[res]):\n",
    "                res = e\n",
    "    return res\n",
    "    \n",
    "print(\"Testing\")\n",
    "percent = {}\n",
    "for true_cname in class_names:\n",
    "    if (true_cname[:4]=='test'):\n",
    "        print(true_cname,len(dataset[true_cname]))\n",
    "        dc = 0\n",
    "        for O in dataset[true_cname]:\n",
    "            score = {cname : round(model.score(O, [len(O)]),3) for cname, model in models.items() if cname[:4] != 'test' }            \n",
    "            if (max_score(score)==true_cname[5:]): dc+=1\n",
    "            print(true_cname,score)\n",
    "        print()\n",
    "        percent[true_cname] = f\"{dc}/{len(dataset[true_cname])}\"\n",
    "\n",
    "        \n",
    "for k, v in percent.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
